# 구글이 제안한 RAG 성능 향상을 위한 ‘충분한 컨텍스트’ 개념

<br>

## 1. 배경: RAG란 무엇인가?
- **RAG (Retrieval-Augmented Generation)**는 
  - 질문에 답할 때, 외부 문서를 먼저 **검색**(Retrieval)하고,
  - 그 문서를 바탕으로 **생성**(Generation)하는 방식의 AI입니다.
- LLM(대형 언어 모델)이 정보를 잘 기억하지 못하므로, 검색된 문서를 함께 주는 방식입니다.

<br>

## 2. 문제점: RAG도 한계가 있다
- 모델이 문서를 받았더라도 **자신 있게 틀린 답**을 내기도 합니다.
- 문서가 길어질수록 **중요한 정보에 집중하지 못하고**, 쓸데없는 내용에 끌리기도 합니다.
- 어떤 문서가 도움이 되었는지 **판별하기 어렵다**는 문제도 있습니다.

<br>

## 3. 구글의 제안: ‘충분한 컨텍스트’ 기준 만들기
- **충분한 컨텍스트(Sufficient Context)**: 질문에 **정확히 답할 수 있을 만큼** 정보를 잘 담은 문서
- **불충분한 컨텍스트(Insufficient Context)**: **정보가 부족하거나 오해할 수 있는** 문서

<br>

### 예시
| 질문 | 컨텍스트 유형 | 설명 |
|------|----------------|------|
| "Lya는 누구와 결혼했나요?" | 충분함 | "Lya는 2020년에 Paul과 결혼했다." |
| | 불충분 | "Lya는 2006년 Tom과 결혼했다가 이혼했다..." (현재 배우자 정보 없음) |

<br>

## 4. 핵심 기술: 자동으로 분류하는 LLM 분류기
- 구글은 질문과 컨텍스트만 보고 **충분한지 자동으로 판단하는 분류기(autorater)**를 만들었음
- **Gemini 1.5 Pro**가 특히 잘 작동하며, **1개 예시만 주어도 잘 분류함(1-shot 학습)**

<br>

## 5. 주요 실험 결과
- 컨텍스트가 충분할수록 정답률이 높음
- 하지만 모델들은 **틀릴 바에야 '모르겠다'고 말하기보다 틀린 답을 말하는 경향**이 있음
- 불충분한 컨텍스트에서는 **환각(hallucination)**이 더 자주 발생

<br>

## 6. 선택적 생성 (Selective Generation) 기법 제안
- **중재 모델(intervention model)**을 먼저 두고, 주 모델이 **답변할지 말지 먼저 판단**
- ‘답하지 말라’는 신호를 주면 잘못된 답변을 줄일 수 있음

<br>

## 7. 추가 미세조정: "모르겠다"를 정답으로
- 일부 예시에서는 정답 대신 **"모르겠다"**를 답으로 학습시켜 모델이 무책임한 답을 피하도록 유도함

<br>

## 8. 성과와 한계
- **정답률이 최대 2~10% 향상**
- 하지만 여전히 모델은 **자신 있게 틀린 답을 내기도 함**
- "모르겠다"는 답변과 **정답률 사이의 균형**을 잡기 위한 더 많은 연구 필요

<br>

## 요약
> 구글은 RAG 시스템에서 답변의 정확성을 높이기 위해, **"충분한 컨텍스트"**라는 기준을 만들고, 이를 자동으로 평가할 수 있는 LLM 기반 도구를 개발했습니다. 이 접근은 RAG의 핵심인 문서 선택 과정부터 더 똑똑하게 만들기 위한 노력입니다.

<br>

## 적용 분야 분류
이 연구는 아래 폴더 구조 기준으로 보면 다음에 해당됩니다:
- **02-NLP** (자연어 질문, 답변 정확도, 문서 이해 중심)
- 확장하면 **03-Multimodal**에서도 응용 가능

<br>

원문 출처: [AI타임스 기사 링크](https://www.aitimes.com/news/articleView.html?idxno=170733)  
2025-05-26

